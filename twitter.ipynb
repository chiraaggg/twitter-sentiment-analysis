import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix
import string
from nltk.corpus import stopwords

# Load the dataset without headers
df = pd.read_csv('twitter_training.csv', header=None) # Ensure you provide the correct path to your dataset

# Assign column names to the dataframe
df.columns = ['no.','account','sentiment','text'] # Adjust column names according to your dataset

# Display the first few rows of the dataset
print(df.head())

# Data preprocessing
# Remove any missing values
df.dropna(inplace=True)

# Function to clean the text data
def clean_text(text):
    text = text.lower()
    text = ''.join([char for char in text if char not in string.punctuation])
    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])
    return text

# Apply the clean_text function to the tweet column
df['cleaned_text'] = df['text'].apply(clean_text)

# Sentiment analysis
# Define the target variable and features
X = df['cleaned_text']
y = df['sentiment']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a pipeline for text processing and model training
pipeline = Pipeline([
    ('vectorizer', CountVectorizer()),
    ('classifier', MultinomialNB())
])

# Train the model
pipeline.fit(X_train, y_train)

# Make predictions
y_pred = pipeline.predict(X_test)

# Evaluate the model
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Data visualization
# Sentiment distribution
sns.countplot(x='sentiment', data=df)
plt.title('Sentiment Distribution')
plt.show()

# Word cloud for positive and negative sentiments
positive_text = ' '.join(df[df['sentiment'] == 'positive']['cleaned_text'])
negative_text = ' '.join(df[df['sentiment'] == 'negative']['cleaned_text'])

if positive_text:
    positive_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_text)
    plt.figure(figsize=(10, 5))
    plt.imshow(positive_wordcloud, interpolation='bilinear')
    plt.title('Positive Sentiment Word Cloud')
    plt.axis('off')
    plt.show()
else:
    print("No positive text data available to generate word cloud.")

if negative_text:
